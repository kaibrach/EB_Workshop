{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification visualizations\n",
    "\n",
    "In this notebook we want to implement our first neural network in tensorflow. Therefore we first have a look at [Tensorflow Playground](https://playground.tensorflow.org)\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/tensorchiefs/dl_book/master/imgs/paper-pen.png\" width=\"60\" align=\"left\" />  \n",
    "\n",
    "**Small Exercise:** We want to implement the Circle Datatype. Therefore just play with the Playground, add Neurons and layers and see what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "%matplotlib inline\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "Here we define some settings for our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# number of samples in the data set\n",
    "N_SAMPLES = 1000\n",
    "# ratio between training and test sets\n",
    "TEST_SIZE = 0.1\n",
    "# number of iterations of the model\n",
    "N_EPOCHS = 50\n",
    "\n",
    "# boundary of the graph\n",
    "GRID_X_START = -1.5\n",
    "GRID_X_END = 1.5\n",
    "GRID_Y_START = -1.5\n",
    "GRID_Y_END = 1.5\n",
    "# output directory is created if not available\n",
    "OUTPUT_DIR = \"02_tensorflow_playground_visualization\"\n",
    "\n",
    "if os.path.exists(OUTPUT_DIR):\n",
    "    shutil.rmtree(OUTPUT_DIR)\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "    \n",
    "else:\n",
    "    os.makedirs(OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Circle dataset\n",
    "We will create the training and test dataset. Therefor we use the `train_test_split` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create circle data with a scale factor of 0.3 for inner and outer circle and add Noise to the data\n",
    "X, y = make_circles(n_samples=N_SAMPLES, factor=.3, noise=.10)\n",
    "\n",
    "# We split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=42)\n",
    "\n",
    "# Plot the figure\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train.ravel(), s=70, cmap=plt.cm.spring, edgecolors='red', alpha=0.5, label=\"Train\");\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test.ravel(), s=70, cmap=plt.cm.winter, edgecolors='yellow', alpha=0.5, label=\"Test\");\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of grid boundaries and storage of loss and accuracy history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.mgrid[GRID_X_START:GRID_X_END:100j,GRID_X_START:GRID_Y_END:100j]\n",
    "grid_2d = grid.reshape(2, -1).T\n",
    "X, Y = grid\n",
    "acc_history = []\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precede the number with zeros, creating a thong of a certain length\n",
    "def makeIndexOfLength(index, length):\n",
    "    indexStr = str(index)\n",
    "    return ('0' * (length - len(indexStr)) + indexStr)\n",
    "\n",
    "# the auxiliary function forming graphs of classification boundaries and change of accuracy\n",
    "def save_model_prediction_graph(epoch, logs):\n",
    "    prediction_probs = model.predict_proba(grid_2d, batch_size=32, verbose=0)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.title('Binary classification with Tensorflow - epoch: ' + makeIndexOfLength(epoch, 3), fontsize=20)\n",
    "    plt.xlabel('X', fontsize=15)\n",
    "    plt.ylabel('Y', fontsize=15)\n",
    "    plt.contourf(X, Y, prediction_probs.reshape(100, 100), alpha = 0.7, cmap=cm.Spectral)\n",
    "    plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train.ravel(), s=50, cmap=plt.cm.Spectral, edgecolors='black')\n",
    "    plt.savefig(\"./\" + OUTPUT_DIR + \"/tf_\" + makeIndexOfLength(epoch, 3) + \".png\")\n",
    "    plt.close()\n",
    "    \n",
    "    acc_history.append(logs['accuracy'])\n",
    "    loss_history.append(logs['loss'])\n",
    "    plt.figure(figsize=(12,8))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.plot(acc_history)\n",
    "    plt.plot(loss_history)\n",
    "    plt.title('Model accuracy and loss - epoch: ' + makeIndexOfLength(epoch, 3), fontsize=20)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.xlim([0,N_EPOCHS])\n",
    "    plt.legend(['accuracy', 'loss'], loc='upper left')\n",
    "    plt.savefig(\"./\" + OUTPUT_DIR + \"/loss_acc_\" + makeIndexOfLength(epoch, 3) + \".png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "Now we will define our fully connected Sequential model.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/tensorchiefs/dl_book/master/imgs/paper-pen.png\" width=\"60\" align=\"left\" />  \n",
    "\n",
    "**Small Exercise:** \n",
    "\n",
    "                  1. Try to build a neural network model as in Tensorflow Playground \n",
    "                     1.1 Add hidden layers (model.add(Dense(NumberOfNeurons, activation='activation_name'))\n",
    "                     2.1 Modify the activation function,  the optimizer and learning rate.\n",
    "                     2.1 Check how many epochs you need to\n",
    "                  2. What happens to the output Gif if you use different activation functions\n",
    "                  3. If necessary modify the Hyperparameters (N_SAMPLES, TEST_SIZE, N_EPOCHS) in Settings\n",
    "                     3.1 Can you reduce the number of Training Epochs? If yes, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "# List of activation functions\n",
    "acti_list = [\n",
    "             tf.keras.activations.relu,\n",
    "             tf.keras.activations.tanh,\n",
    "             tf.keras.activations.elu,\n",
    "            ]\n",
    "\n",
    "# Choose an activation function\n",
    "acti = acti_list[1]  # \n",
    "print(f\"Using Activation: {acti.__name__}\\n\")\n",
    "\n",
    "# Creating a Sequential model\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=2,activation=acti))\n",
    "############ YOUR CODE HERE ############\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a callback function that plots images at every epoch\n",
    "testmodelcb = tf.keras.callbacks.LambdaCallback(on_epoch_end=save_model_prediction_graph)\n",
    "earlystoppingcb = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",patience=3, verbose=1, mode=\"min\",min_delta=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network\n",
    "We will use `binary_crossentropy` because we have a model of two classes (The inner and the outer cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "# List of optimizers\n",
    "opti_list = [\n",
    "             tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "             tf.keras.optimizers.Adamax(learning_rate=LEARNING_RATE),\n",
    "             tf.keras.optimizers.SGD(learning_rate=LEARNING_RATE)\n",
    "            ]\n",
    "\n",
    "# Choose an optimizer\n",
    "opti = opti_list[0]\n",
    "print(f\"Using Optimizer: {opti.__class__.__name__}\")\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=opti, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=N_EPOCHS, verbose=0, callbacks=[testmodelcb,\n",
    "                                                                             #earlystoppingcb\n",
    "                                                                            ])\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Gif \n",
    "We want to create a gif of our stored output to see what happens at every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "def create_gif(name,output):\n",
    "    # filepaths\n",
    "    fp_in = os.path.join(os.getcwd(),OUTPUT_DIR+os.sep)+name+\"*.png\"\n",
    "    fp_out = os.path.join(os.getcwd(),OUTPUT_DIR+os.sep)+name+output+\".gif\"\n",
    "\n",
    "    # https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html#gif\n",
    "    img, *imgs = [Image.open(f) for f in sorted(glob.glob(fp_in))]\n",
    "    gif = img.save(fp=fp_out, format='GIF', append_images=imgs,\n",
    "             save_all=True, duration=200, loop=0)\n",
    "    \n",
    "    # Remove all png files\n",
    "    [os.remove(f) for f in sorted(glob.glob(fp_in))]\n",
    "\n",
    "    return fp_out\n",
    "\n",
    "tf_gif = create_gif(\"tf\",f\"_{opti.__class__.__name__.lower()}_{acti.__name__}\")\n",
    "loss_acc_gif = create_gif(\"loss_acc\",f\"_{opti.__class__.__name__.lower()}_{acti.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import IPython.display as display\n",
    "## Read images from file (because this is binary, maybe you can find how to use ByteIO) but this is more easy\n",
    "img1 = open(tf_gif, 'rb').read()\n",
    "img2 = open(loss_acc_gif, 'rb').read()\n",
    "## Create image widgets. You can use layout of ipywidgets only with widgets.\n",
    "## Set image variable, image format and dimension.\n",
    "wi1 = widgets.Image(value=img1, format='png')#, width=500, height=500)\n",
    "wi2 = widgets.Image(value=img2, format='png')#, width=500, height=500)\n",
    "## Side by side thanks to HBox widgets\n",
    "sidebyside = widgets.HBox([wi1, wi2])\n",
    "## Finally, show.\n",
    "display.display(sidebyside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
