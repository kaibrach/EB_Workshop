{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MvQWEPI9CH7H"
   },
   "source": [
    "# Classification using FCN and CNN\n",
    "In this notebook we want to use 2 different approaches for doing classification on 2D image data. Further we want to plot our accuracy and and test our network when importing own handwritten digits\n",
    "1. We do classification on a fully connected network **FCN**\n",
    "2. We do classification on a convolutional neural network **CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1619,
     "status": "ok",
     "timestamp": 1601025605915,
     "user": {
      "displayName": "Philipp Schmieder",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GilNjhUXq83sj1BsL2I_E5qGbVh7zCWNq5dOjxMMA=s64",
      "userId": "17931796020654859734"
     },
     "user_tz": -120
    },
    "id": "VZJzQXtUCH7L",
    "outputId": "83dcaace-d500-4645-cdff-65dc5e2665fc"
   },
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Commonly used modules\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Images, plots, display, and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import IPython\n",
    "from six.moves import urllib\n",
    "%reload_ext tensorboard\n",
    "print(tf.__version__)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wtYF5pJXCH8R"
   },
   "source": [
    "# Creating the dataset\n",
    "\n",
    "The MNIST dataset contains 70,000 grayscale images of handwritten digits at a resolution of 28 by 28 pixels. The task is to take one of these images as input and predict the most likely digit contained in the image (along with a relative confidence in this prediction):\n",
    "\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"Pictures/mnist_numbers.png\" width=\"500\" height=\"400px\" align=\"left\"> </td>\n",
    "<td> <img src=\"Pictures/nn.png\" width=\"500\" align=\"right\"> </td>\n",
    "</tr></table>\n",
    "\n",
    "Now, we load the dataset. The images are 28x28 NumPy arrays, with pixel values ranging between 0 and 255. The *labels* are an array of integers, ranging from 0 to 9.\n",
    "\n",
    "## Preprocessing/Normalization\n",
    "We normalize the images values to a range of 0 to 1 before feeding to the neural network model. For this, we divide the values by 255. It's important that the *training set* and the *testing set* are preprocessed in the same way.\n",
    "Main purpose of normalization is to make computation efficient and have a faster convergence by reducing values between 0 to 1. The result is that the network learns faster, reduce the chances of getting stuck in local optima and **could** lead to higher accurracy (Thats not always the case)\n",
    "\n",
    "* **Allows higher learning rates**: \n",
    "Gradient descent usually requires small learning rates for the network to converge, this is because of gradient vanishing problem. As networks get deeper, gradients get smaller during back propagation, and so require even more iterations to converse(gradient vanishing problem). Using normalisation allows much higher learning rates, increasing the speed at which networks train.\n",
    "\n",
    "* **Makes weights easier to initialise**: Choice of initial weights are very important crucial and can also influence training time. Weight initialisation can be difficult, especially when creating deeper networks. Normalisation helps reduce the sensitivity to the initial starting weights.\n",
    "\n",
    "* **Makes more activation functions viable**: Some activation functions don’t work well in certain situations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(imgs): # should work for both a single image and multiple images\n",
    "    if imgs.shape != [(28, 28, 1)] and imgs.ndim == 3:\n",
    "        imgs = cv2.cvtColor(imgs, cv2.COLOR_RGB2GRAY)\n",
    "        imgs = cv2.resize(imgs,(28,28))\n",
    "        imgs = cv2.bitwise_not(imgs)\n",
    "    sample_img = imgs if len(imgs.shape) == 2 else imgs[0]\n",
    "    assert sample_img.shape in [(28, 28, 1), (28, 28)], sample_img.shape # make sure images are 28x28 and single-channel (grayscale)\n",
    "    return imgs / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ntuOwYNcCH8S"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "print(f\"train_images: {train_images.shape}\")\n",
    "print(f\"test_images: {test_images.shape}\")\n",
    "\n",
    "# reshape images to specify that it's a single channel image\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
    "\n",
    "print(f\"train_images: {train_images.shape}\")\n",
    "print(f\"test_images: {test_images.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gOkWmsCmCH8h"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/tensorchiefs/dl_book/master/imgs/paper-pen.png\" width=\"60\" align=\"left\" />  \n",
    "\n",
    "**Exercise**: Display the first 5 images from the *training set* and display the class name below each image. Verify that the data is in the correct format and we're ready to build and train the network.\n",
    "\n",
    "**Hint**: Some helpful function templates\n",
    "```python \n",
    "            # loop function\n",
    "            for i in iterable:\n",
    "                pass\n",
    "            \n",
    "            # subplots\n",
    "            plt.subplot(nrows, ncols, index)\n",
    "                        \n",
    "            # plot function\n",
    "            plt.imshow(image, cmap=plt.cm.binary)\n",
    "```\n",
    "\n",
    "<details>\n",
    "    <summary> <b>Click here for one possible solution</b></summary>\n",
    "    \n",
    "```python\n",
    "plt.figure(figsize=(10,2))\n",
    "for i,x in enumerate(train_images[0:5]):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x, cmap=plt.cm.binary)\n",
    "    plt.xlabel(train_labels[i])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4dkGPbCqCH8i",
    "outputId": "14e535ea-08e9-4806-af10-6ec701489171"
   },
   "outputs": [],
   "source": [
    "############ YOUR CODE HERE ############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Classification of MNIST using Fully Connected Neural Network\n",
    "The “dense” or the “fully-connected” neural network (NN) is the simplest form of neural net where a neuron in a given layer is connected to all the neurons in the previous and the next layers as shown in the below diagram.\n",
    "\n",
    "<img src=\"Pictures/mnist_2layers.png\" width=\"500px\">\n",
    "\n",
    "The dense NN can only take one-dimensional (1D) input and hence the 2D inputs like images have to be “flattened” as shown in the diagram before feeding them to the dense NN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_vector_size  = train_images.shape[1]*train_images.shape[2]\n",
    "print(f\"Image Vector Size: {image_vector_size}\")\n",
    "\n",
    "# Reshape the training_images\n",
    "X_train = train_images.reshape((-1, image_vector_size)) # Flatten the 2D input to 1D \n",
    "                                                        # One shape dimension can be -1. In this case, the value \n",
    "                                                        # is inferred from the length of the array and remaining \n",
    "                                                        # dimensions.\n",
    "print(f\"Training 1D input shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/tensorchiefs/dl_book/master/imgs/paper-pen.png\" width=\"60\" align=\"left\" />  \n",
    "\n",
    "**Exercise**: Create a fully connected (Dense Layers) neural network model for classifing the MNIST numbers dataset.\n",
    "The last layer activation **must** be **softmax**. \n",
    "1. Create a number of hidden layers (Dense)\n",
    "2. Specify the activation function for each hidden layer\n",
    "3. Specify the last layer output for the multi classification problem\n",
    "4. Compile your model and choose a proper (Check if your `train_labels` are `one-hot-encoded or sparse`)                       \n",
    "    * *Loss function* - measures how accurate the model is during training, we want to minimize this with the optimizer.\n",
    "        * \"sparse_categorical_crossentropy\" if `labels not one hot encoded`\n",
    "        * \"categorical_crossentropy\" `if labels one hot encoded`\n",
    "    * *Optimizer* - how the model is updated based on the data it sees and its loss function.\n",
    "    * *Metrics* - used to monitor the training and testing steps. \"accuracy\" is the fraction of images that are correctly classified.\n",
    "\n",
    "5. Train your model for a number of epochs or using a callback_function (e.g. EarlyStopping)\n",
    "\n",
    "**Hint**: One-Hot enoded `train_labels` are zero based an look like this: `3 = [0,0,0,1]`\n",
    "```python\n",
    "labels_cat = keras.utils.to_categorical(labels,num_classes)\n",
    "# Example\n",
    "a = tf.keras.utils.to_categorical([0, 1, 2, 3], num_classes=4)\n",
    "```\n",
    "\n",
    "<details>\n",
    "<summary><b>Click here for one possible solution</b></summary>\n",
    "    \n",
    "```python\n",
    "# Create a Sequantial model\n",
    "model = keras.Sequential()\n",
    "# Add an Input layer to the model using the flattened shape of the dataset\n",
    "model.add(Input(shape=(X_train.shape[1]), name='input'))\n",
    "# First hidden dense layer with 256 logits\n",
    "model.add(Dense(256, activation='relu'))\n",
    "# First hidden dense layer with 256 logits\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# Third hidden dense layer with 64 logits\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# output a softmax to squash the matrix into output probabilities\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model\n",
    "Now we want to create the Fully Connected Network for this classification task. Because we want the evaluate the data normalization we create two different models\n",
    "1. `model_norm`: Model will be trained with normalized data\n",
    "2. `model_unnorm`: Model will be trained without normalized input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name:str):\n",
    "    # Resets all state generated by Keras\n",
    "    keras.backend.clear_session()\n",
    "    ############ YOUR CODE HERE ############\n",
    "    \n",
    "    # Create a Sequantial model\n",
    "    m = keras.Sequential(name=model_name)\n",
    "    # Add an Input layer to the model using the flattened shape of the dataset\n",
    "    m.add(Input(shape=(X_train.shape[1]), name='input'))\n",
    "    # First hidden dense layer with 256 logits\n",
    "    m.add(Dense(256, activation='relu'))\n",
    "    # First hidden dense layer with 256 logits\n",
    "    m.add(Dense(128, activation='relu'))\n",
    "    # Third hidden dense layer with 64 logits\n",
    "    m.add(Dense(64, activation='relu'))\n",
    "    # output a softmax to squash the matrix into output probabilities\n",
    "    m.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    m.compile(optimizer='adam', \n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return m\n",
    "\n",
    "# Create the models \n",
    "model_norm = get_model(\"model_norm\")\n",
    "model_unnorm = get_model(\"model_unnorm\")\n",
    "\n",
    "# Print the Model summary\n",
    "model_norm.summary()\n",
    "model_unnorm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "Next we want to train both model using the the `normalized` and `not_normalized` dataset with same hyperparameters\n",
    "\n",
    "### Training model with normalized training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# We create a tensorboard callback for model evaluation\n",
    "logdir = os.path.join(\"logs_FCN\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "# Create some additional callbacks e.g. EarlyStopping and add it to the callbacks list \n",
    "# Press Umschalt + Tab for retrieving function details\n",
    "\n",
    "# Create normalized traing data\n",
    "X_train = preprocess_images(train_images)\n",
    "X_train = X_train.reshape((-1, image_vector_size))\n",
    "\n",
    "# Start Training\n",
    "history = model_norm.fit(x=X_train, y=train_labels,  # Training images and labels\n",
    "                    validation_split=0.1,       # Fraction of the training data to be used as validation data\n",
    "                    epochs=5,                   # Number of epochs to train the model.\n",
    "                    batch_size=128,             # Number of samples per gradient update.\n",
    "                    callbacks=[                 # List of `keras.callbacks.Callback` instances to apply during training\n",
    "                        tensorboard_callback\n",
    "                    ],\n",
    "                    verbose=1                   #  0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model with unnormalized training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create not normalized training data\n",
    "X_train_unnorm = train_images.reshape((-1, image_vector_size))\n",
    "\n",
    "# Start Training\n",
    "history = model_unnorm.fit(x=X_train_unnorm, y=train_labels,  # Training images and labels\n",
    "                    validation_split=0.1,       # Fraction of the training data to be used as validation data\n",
    "                    epochs=5,                   # Number of epochs to train the model.\n",
    "                    batch_size=128,             # Number of samples per gradient update.\n",
    "                    callbacks=[                 # List of `keras.callbacks.Callback` instances to apply during training\n",
    "                        tensorboard_callback\n",
    "                    ],\n",
    "                    verbose=1                   #  0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the model with Tensorboard\n",
    "Now we want to visualize our model using tensorboard. Just execute the next cell and see what happens.\n",
    "\n",
    "**Hint**: If tensorboard did not start, interrupt the kernel and run the cell again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logs --port 6006 --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "Now we want to evaluate our model against the test data (test_images). Therefore we use our trained model and call `model.evaluate()`. The `evaluate()` function returns the loss value & metrics values for the model in test mode.\n",
    "\n",
    "**Hint:** \n",
    "1. Prepare the Test Dataset for `normalized` and `unnormalized model`\n",
    "1. If you used \"one hot\" encoded `train_labels` you have to convert the `test_labels` also as \"one hot\" encoded befor passing to the `evaluate()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\"*30)\n",
    "print(f\"Evaluate: {model_norm.name}\")\n",
    "print(f\"Testing input shape: {test_images.shape[1:]}\")\n",
    "print(f\"Needed Model input shape:{model_norm.input_shape[1:]}\")\n",
    "\n",
    "############ YOUR CODE HERE ############\n",
    "# Prepare the test_images that is suits the model input shape\n",
    "X_test = \n",
    "\n",
    "test_loss, test_acc = model_norm.evaluate(X_test, test_labels)\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "print(\"-\"*30)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "print(\"-\"*30)\n",
    "print(f\"Evaluate: {model_unnorm.name}\")\n",
    "print(f\"Testing input shape: {test_images.shape[1:]}\")\n",
    "print(f\"Needed Model input shape:{model_norm.input_shape[1:]}\")\n",
    "\n",
    "############ YOUR CODE HERE ############\n",
    "#Prepare the test_images that is suits the model input shape\n",
    "X_test_unnorm = \n",
    "test_loss, test_acc = model_unnorm.evaluate(X_test_unnorm, test_labels)\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary> <b>Click here for one possible solution</b></summary>\n",
    "    \n",
    "``` python\n",
    "# Normalized Data\n",
    "X_test = preprocess_images(test_images)\n",
    "X_test = X_test.reshape((-1, image_vector_size))\n",
    "\n",
    "# Unnormalized Data\n",
    "X_test_unnorm = test_images.reshape((-1, image_vector_size))\n",
    "```\n",
    "</details>\n",
    "\n",
    "As mentioned above. You see that you have higher accuracy for the normalized model `model_norm` when comparing the accuracy. This is due to the fact that the loss converges faster and need less training epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction\n",
    "Last but not least we want to check if our model really does what we expect. Therefore we can do some predictions on our model using the `test_images` already prepared in `X_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/tensorchiefs/dl_book/master/imgs/paper-pen.png\" width=\"60\" align=\"left\" />  \n",
    "\n",
    "**Exercise**: \n",
    "\n",
    "         1. Do a prediction for one random test_image (Dont forget the batch-dimension :-)) and print the output\n",
    "         2. Plot the test_image, test_label and the network prediction with highest confidence (y_pred_label)\n",
    "            (Keep in mind you get 10 outputs) --> See **Hint**\n",
    "         3. Find images in the test_images dataset that are not predicted correctly and plot some\n",
    "         4. Question: What could we do to decrease the missclassification?\n",
    "\n",
    "**Hint**: We have a multi class prediction of 10 images.\n",
    "The maximum value, the value with the highest confidence within the predictions, can be extracted using numpy `argmax` function. `argmax` returns the indices of the maximum values along an axis.\n",
    "\n",
    "<details>\n",
    "    <summary> <b>Click here for one possible solution</b></summary>\n",
    "    \n",
    "``` python\n",
    "model = model_norm\n",
    "    \n",
    "# 1. Do a prediction for one random test_image\n",
    "idx = np.random.choice(X_test.shape[0],size=1)\n",
    "y_pred = model.predict(X_test[idx]) \n",
    "#y_pred = model.predict(np.expand_dims(X_test[0],0)) # shape is (1,784)\n",
    "#y_pred = model.predict(X_test[[0]])                 # shape is (1,784) \n",
    "y_true_label = test_labels[idx]\n",
    "y_pred_label = np.argmax(y_pred,1)\n",
    "print(f\"Pred: {y_pred}\")\n",
    "print(f\"True_label: {y_true_label} Pred_label: {y_pred_label}\")    \n",
    " \n",
    "\n",
    "# 2. Plot the test_image and the network prediction with highest confidence\n",
    "plt.figure(figsize=(10,2))\n",
    "for i,x in enumerate(idx):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    \n",
    "    # Predict the random image\n",
    "    y_pred = model.predict(X_test[[x]])     # use [x] or np.expand_dims(x,0)\n",
    "    y_pred_label = np.argmax(y_pred,axis=1)[0] # Get the highest confidence out out the prediction\n",
    "    y_true_label = test_labels[x]\n",
    "    \n",
    "    # Show the image\n",
    "    plt.imshow(X_test[x].reshape(28, 28), cmap=plt.cm.binary)\n",
    "    plt.title(f\"True: {y_true_label}\")\n",
    "    plt.xlabel(f\"Pred:{y_pred_label}\")\n",
    "    \n",
    "# 3. Find images in the test_images dataset that are not predicted correctly and plot some\n",
    "# Predict all images\n",
    "y_pred_label = np.argmax(a=model.predict(X_test),axis=1)\n",
    "\n",
    "#Get incorred classified predictions\n",
    "y_pred_idx_incorr = np.nonzero(y_pred_label != test_labels)[0]  \n",
    "\n",
    "#Get a specific class that is classified incorrect \n",
    "y_pred_idx_equals = [a for a in y_pred_idx_incorr if test_labels[a] == 4]\n",
    "\n",
    "plt.figure(figsize=(10,2))\n",
    "for i,x in enumerate(y_pred_idx_incorr[3:8]):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    \n",
    "    # Predict the random image\n",
    "    y_pred = model.predict(X_test[[x]])     # use [x] or np.expand_dims(x,0)\n",
    "    y_pred_label = np.argmax(y_pred,axis=1)[0] # Get the highest confidence out out the prediction\n",
    "    y_true_label = test_labels[x]\n",
    "    \n",
    "    # Show the image\n",
    "    plt.imshow(X_test[x].reshape(28, 28), cmap=plt.cm.binary)\n",
    "    plt.title(f\"True: {y_true_label}\")\n",
    "    plt.xlabel(f\"Pred:{y_pred_label}\")\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set the model to the normalized_model\n",
    "model = model_norm\n",
    "\n",
    "############ YOUR CODE HERE ############\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with Confusion matrix\n",
    "A confusion matrix or error matrix is a table that is often used to describe the performance of a classification model \n",
    "(or \"classifier\") on a set of test data for which the true values are known. The confusion matrix itself is relatively \n",
    "simple to understand, but the related terminology can be confusing.\n",
    "\n",
    "<img src=\"Pictures/confusion_matrix2.png\" width=\"500px\">\n",
    "\n",
    "What can we learn from this matrix?\n",
    "\n",
    "* There are two possible predicted classes: `yes` and `no`. If we were predicting the presence of `Covid-19`, for example, `yes` would mean they have the disease, and `no` would mean they don't have the disease.\n",
    "* The classifier made a total of 165 predictions (e.g., 165 patients were being tested for the presence of Corona).\n",
    "* Out of those 165 cases, the classifier predicted \"yes\" 110 times, and \"no\" 55 times.\n",
    "* In reality, 105 patients in the sample have the disease, and 60 patients do not.\n",
    "\n",
    "Let's now define the most basic terms, which are whole numbers (not rates):\n",
    "\n",
    "* true positives (TP): These are cases in which we predicted yes (they have the disease), and they do have the disease.\n",
    "* true negatives (TN): We predicted no, and they don't have the disease.\n",
    "* false positives (FP): We predicted yes, but they don't actually have the disease. (Also known as a \"Type I error.\")\n",
    "* false negatives (FN): We predicted no, but they actually do have the disease. (Also known as a \"Type II error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, num_classes):\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "    import itertools\n",
    "    plt.figure(figsize=(10,6))\n",
    "    # Build the plot\n",
    "    cm=confusion_matrix(y_true,y_pred)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    tick_marks = np.arange(len(num_classes))\n",
    "    plt.xticks(tick_marks, tick_marks, rotation=45)\n",
    "    plt.yticks(tick_marks, tick_marks)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    misclass = 1. - accuracy\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.title(f\"Confusion Matrix \\naccuracy={accuracy:0.4f}; misclass={misclass:0.4f}\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict all Test images\n",
    "model = model_norm\n",
    "y_pred = model.predict(X_test)\n",
    "y_true_labels = test_labels\n",
    "y_pred_labels =  np.argmax(y_pred,1)# YOUR_TURN\n",
    "print(\"y_true_labels shape:\",y_true_labels.shape)\n",
    "print(\"y_pred shape:\",y_pred.shape)\n",
    "print(\"y_pred_labels shape:\",y_pred_labels.shape)\n",
    "\n",
    "plot_confusion_matrix(y_true_labels,\n",
    "                      y_pred_labels,\n",
    "                      np.unique(y_true_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "To-DFyC6CH8L"
   },
   "source": [
    "# Part 2: Classification of MNIST with Convolutional Neural Networks\n",
    "\n",
    "Next, let's build a convolutional neural network (CNN) classifier to classify images of handwritten digits in the MNIST dataset with a twist where we test our classifier on high-resolution hand-written digits from outside the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "As9XZZqsCH8q"
   },
   "source": [
    "### Build the model\n",
    "<img src=\"https://raw.githubusercontent.com/tensorchiefs/dl_book/master/imgs/paper-pen.png\" width=\"60\" align=\"left\" />  \n",
    "\n",
    "**Exercise:** Now build a very simple Convolutional neural network that looks like this: \n",
    "<img src=\"Pictures/Class_CNN.png\" width=\"700px\" > \n",
    "\n",
    "1. Try to figure out the `filter` and the `pooling sizes` yourself using the picture above. All the activations inside the layers should be 'relu' and the last dense layer again 'softmax'\n",
    "2. Compile your model and choose a proper                        \n",
    "    * *Loss function* - measures how accurate the model is during training, we want to minimize this with the optimizer.\n",
    "        * \"sparse_categorical_crossentropy\" if labels not one hot encoded\n",
    "        * \"categorical_crossentropy\" if labels one hot encoded    \n",
    "    * *Optimizer* - how the model is updated based on the data it sees and its loss function.\n",
    "    * *Metrics* - used to monitor the training and testing steps. \"accuracy\" is the fraction of images that are correctly classified.\n",
    "3. Train your model for a number of epochs or using a callback_function (e.g. EarlyStopping)\n",
    "\n",
    "**Hint**: To encode the labels as \"one hot\" (categorical) use \n",
    "```python\n",
    "keras.utils.to_categorical(labels,num_classes)\n",
    "```\n",
    "\n",
    "<details>\n",
    "<summary><b>Click here for one possible solution</b></summary>\n",
    "    \n",
    "```python\n",
    "model = keras.Sequential()\n",
    "# 32 convolution filters used each of size 3x3\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# choose the best features via pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# 64 convolution filters used each of size 3x3\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# choose the best features via pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# flatten since too many dimensions, we only want a classification output\n",
    "model.add(Flatten())\n",
    "# fully connected to get all relevant data\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# one more dropout\n",
    "# output a softmax to squash the matrix into output probabilities\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bRITwgRnCH8r"
   },
   "outputs": [],
   "source": [
    "# Resets all state generated by Keras\n",
    "keras.backend.clear_session()\n",
    "\n",
    "############ YOUR CODE HERE ############\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9D1tzdAwCH85"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "Training the neural network model requires the following steps:\n",
    "\n",
    "1. Feed the training data to the model—in this example, the `train_images` and `train_labels` arrays.\n",
    "2. The model learns to associate images and labels.\n",
    "3. We ask the model to make predictions about a test set—in this example, the `test_images` array. We verify that the predictions match the labels from the `test_labels` array. \n",
    "\n",
    "To start training,  call the `model.fit` method—the model is \"fit\" to the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f-AfdC4CCH86",
    "outputId": "2a9def2b-534f-4928-b220-751197abc686"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "# We create a tensorboard callback for model evaluation\n",
    "logdir = os.path.join(\"logs_CNN\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "# Create some additional callbacks e.g. EarlyStopping and add it to the callbacks list \n",
    "# Press Umschalt + Tab for retrieving function details\n",
    "\n",
    "# YOUR_TURN: Create normalized traing data\n",
    "X_train = preprocess_images(train_images)\n",
    "X_test = preprocess_images(test_images)\n",
    "\n",
    "# Start training\n",
    "history = model.fit(x=X_train, y=train_labels,  # Training images and labels\n",
    "                    validation_split=0.1,       # Fraction of the training data to be used as validation data\n",
    "                    epochs=5,                   # Number of epochs to train the model.\n",
    "                    batch_size=128,             # Number of samples per gradient update.\n",
    "                    callbacks=[                 # List of `keras.callbacks.Callback` instances to apply during training\n",
    "                        tensorboard_callback\n",
    "                    ],\n",
    "                    verbose=1                   #  0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the model with Tensorboard\n",
    "Now we want to visualize our model using tensorboard. Just execute the next cell and see what happens.\n",
    "\n",
    "**Hint**: If tensorboard did not start, interrupt the kernel and run the cell again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logs --port 6007 --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eUzA1mpKCH8_"
   },
   "source": [
    "As the model trains, the loss and accuracy metrics are displayed. This model reaches an accuracy of about 98.68% on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eehP8cSmCH9B"
   },
   "source": [
    "## Evaluate the model\n",
    "Now we want to evaluate our model against the test data (test_images). Therefore we use our trained model and call `model.evaluate()`. The `evaluate()` function returns the loss value & metrics values for the model in test mode.\n",
    "\n",
    "**Hint:** If you used \"one hot\" encoded `train_labels` you have to convert the `test_labels` also as \"one hot\" encoded befor passing to the `evaluate()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fGXb-8WGCH9B",
    "outputId": "aaa6ef72-1dc7-4f11-8e1e-3bfbb4ddb5eb"
   },
   "outputs": [],
   "source": [
    "print(f\"Testing input shape: {test_images.shape[1:]}\")\n",
    "print(f\"Needed Model input shape:{model.input_shape[1:]}\")\n",
    "\n",
    "# YOUR_TURN: Prepare the test_images that is suits the model input shape\n",
    "#X_test = \n",
    "\n",
    "print(f\"Testing 1D input shape: {X_test.shape}\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, test_labels)\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with Confusion matrix\n",
    "Evaluate the CNN with the confusion matrix. Do you see any differences to the FCN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ivfsyxzvaE1r"
   },
   "outputs": [],
   "source": [
    "# Predict all Test images\n",
    "y_pred = model.predict(X_test)\n",
    "y_true_labels = test_labels\n",
    "y_pred_labels =  np.argmax(y_pred,1)# YOUR_TURN\n",
    "print(\"y_true_labels shape:\",y_true_labels.shape)\n",
    "print(\"y_pred shape:\",y_pred.shape)\n",
    "print(\"y_pred_labels shape:\",y_pred_labels.shape)\n",
    "\n",
    "# YOUR_TURN: Plot the Confusion matrix\n",
    "plot_confusion_matrix(y_true_labels,\n",
    "                      y_pred_labels,\n",
    "                      np.unique(y_true_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0K4T-7UzCH9J"
   },
   "source": [
    "Often times, the accuracy on the test dataset is a little less than the accuracy on the training dataset. This gap between training accuracy and test accuracy is an example of *overfitting*. In our case, the accuracy is better at 99.19%! This is, in part, due to successful regularization accomplished with the Dropout layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_MGXVbPCH9K"
   },
   "source": [
    "## Make predictions\n",
    "\n",
    "With the model trained, we can use it to make predictions about some images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_with_bar(preds, img, with_bar=True):    \n",
    "    from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "    \n",
    "    INCLUDED_LABELS = np.unique(test_labels)\n",
    "    \n",
    "    def autolabel(rects,ax):\n",
    "        \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            perc = height*100\n",
    "            ax.annotate('{:2.2f}%'.format(perc),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  # 3 points vertical offset\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')    \n",
    "    # Get the current axis\n",
    "    f = plt.gcf()\n",
    "    f.set_size_inches(10,10)\n",
    "    ax = plt.gca()\n",
    "\n",
    "    font_size=16\n",
    "\n",
    "    '''Plot the current image'''\n",
    "    ax.imshow(img, cmap=plt.cm.binary)\n",
    "    color = 'red'\n",
    "    \n",
    "    predicted_label = np.argmax(preds)\n",
    "    ax.set_xlabel(\"Pred: {} {:2.2f}% \".format(INCLUDED_LABELS[predicted_label],\n",
    "                                100*np.max(preds)),\n",
    "                                color=color, fontsize=font_size)\n",
    "    \n",
    "    ax.grid(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    ''' Create an divider and add the bar to the right'''   \n",
    "    if with_bar:\n",
    "        ax_divider = make_axes_locatable(ax)\n",
    "        cax = ax_divider.append_axes(\"right\", size=\"170%\", pad=\"2%\")\n",
    "        ax.grid(False)\n",
    "        \n",
    "        ''' Plot the distribution'''\n",
    "        pred_plot = cax.bar(INCLUDED_LABELS, preds, color=\"#777777\")\n",
    "        \n",
    "        \n",
    "        ''' Here we check the if the indices are correct'''        \n",
    "        pred_plot[predicted_label].set_color('red')       \n",
    "        \n",
    "        cax.set_xticks(np.arange(len(INCLUDED_LABELS)))\n",
    "        cax.set_xticklabels(INCLUDED_LABELS,rotation=45,fontsize=font_size)\n",
    "        cax.set_yticks([])\n",
    "        cax.set_ylim(0.0,1.1)\n",
    "\n",
    "        # put the y-values on top of the bar\n",
    "        autolabel(pred_plot,cax) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it with your own Image\n",
    "<img src=\"https://raw.githubusercontent.com/tensorchiefs/dl_book/master/imgs/paper-pen.png\" width=\"60\" align=\"left\" />  \n",
    "\n",
    "**Exercise:** You can now try to predict on your images. Open `template.png` in `Test_Pictures` folder with paint for example and draw a number between 0 and 9. You then can read it into the Notebook by putting it in your workshop folder. \n",
    "Keep in mind that we trained our Neural Network on Images with the shape (28,28,1), you might have to resize your own image. (or use the preprocess_images function further up in the script ;) )\n",
    "\n",
    "1. Save your image as \"your_name\".png to `Test_Pictures` folder and\n",
    "2. What do the confidence tell you?\n",
    "3. What happens if you use switch colors (Black background, white digit)\n",
    "4. What happens if you load an blank (white image)\n",
    "3. Share your images with your colleagues. What are their predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your image name \n",
    "image_filename = \"kai.png\"\n",
    "\n",
    "# Read and preprocess the image\n",
    "test = cv2.imread(\"Test_Pictures/\"+image_filename)\n",
    "test = preprocess_images(test)\n",
    "test = np.atleast_3d(test)  # Add channel dimension\n",
    "\n",
    "# Predict your image\n",
    "preds = model.predict(np.expand_dims(test,axis=0))[0] # Add Batch Dimension\n",
    "\n",
    "# Plot the image with all confidences\n",
    "plot_image_with_bar(preds,test)\n",
    "# #print(f\"Your picture shows the Number {np.argmax(preds)} with {preds[0,np.argmax(preds)]} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where is the network looking at?\n",
    "\n",
    "What parts of the images are interesting for the network class prediction? \n",
    "The inside of the network is one of the most interesting parts. Now we want to do a small vizualization of the intermediate layer outputs by calculating the gradients of the model output with respect to the layer.\n",
    "We call this the `class_activation_map (CAM)` of the network.\n",
    "\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"Pictures/gradcam1.png\" width=\"500\" height=\"400\" align=\"center\" style=\"width:60%\">\n",
    "  </div>\n",
    "</div>\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <img src=\"Pictures/gradcam_chest.png\" width=\"500\" height=\"400\" align=\"left\" style=\"width:50%\">\n",
    "  </div>\n",
    "   <div class=\"column\">\n",
    "    <img src=\"Pictures/gradcam_gp.png\" width=\"500\" height=\"400\" align=\"center\" style=\"width:50%\">\n",
    "    </div>\n",
    "  </div>\n",
    "</div> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Activation Map (CAM)\n",
    "Class activation maps are a simple technique to get the discriminative image regions used by a CNN to identify a specific class in the image. In other words, a class activation map (CAM) lets us see which regions in the image were relevant to this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Create a random image\n",
    "#idx = np.random.choice(X_test.shape[0],1) 4132=6\n",
    "idx = 4132\n",
    "image = test#X_test[idx] # YOUR_TEST_IMAGE \n",
    "if image.ndim < 4:\n",
    "    image = keras.preprocessing.image.img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "upsample_shape = (300,300)\n",
    "\n",
    "\n",
    "# We are creating a new model that is able to predict intermediate layer outputs as well as the model output\n",
    "conv_layer = model.get_layer(\"conv2d_1\")\n",
    "cam_model = tf.keras.models.Model([model.inputs], [conv_layer.output, model.output])\n",
    "\n",
    "\n",
    "# Now we calulate the gradient of our network loss with w.r.t. to the layer output\n",
    "with tf.GradientTape() as tape:\n",
    "    inputs = tf.cast(image, tf.float32)\n",
    "    (convOuts, preds) = cam_model(inputs)  # preds after softmax\n",
    "    loss = preds[:, np.argmax(preds[0])]\n",
    "\n",
    "# This is the gradient of the top predicted class with regard to\n",
    "# the output feature map of the last conv layer\n",
    "grads = tape.gradient(loss, convOuts)\n",
    "\n",
    "# This is a vector where each entry is the mean intensity of the gradient\n",
    "# over a specific feature map channel\n",
    "pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "# Remove the batch dimension\n",
    "convOuts = convOuts[0]\n",
    "\n",
    "# Now we can compute the CAM by multiplying the pooled_grads with the Convolution Outputs\n",
    "cam = tf.reduce_mean(tf.multiply(pooled_grads, convOuts), axis=-1)\n",
    "\n",
    "# grads = grads[0]\n",
    "# #Normalize the gradients between \n",
    "# #norm_grads = tf.divide(grads, tf.reduce_mean(tf.square(grads)) + tf.constant(1e-5))\n",
    "# norm_grads = tf.divide(grads, (tf.sqrt(tf.reduce_mean(tf.square(grads))) + 1e-5))\n",
    "# #Apply Global Averave Pooling Technique\n",
    "# pooled_grads = tf.reduce_mean(norm_grads, axis=(0, 1))\n",
    "# # Now we can compute the CAM by multiplying the pooled_grads with the Convolution Outputs\n",
    "# cam = tf.reduce_sum(tf.multiply(pooled_grads, convOuts), axis=-1)\n",
    "\n",
    "\n",
    "# Apply ReLU on cam data\n",
    "cam = np.maximum(cam, 0)\n",
    "if np.max(cam) != 0:\n",
    "    cam = cam / np.max(cam)\n",
    "#cam = cam.transpose((1,2,0))\n",
    "\n",
    "# Resize the CAM and convert the CAM to 3D a\n",
    "cam = cv2.resize(cam, upsample_shape, interpolation=cv2.INTER_LINEAR)\n",
    "cam = np.expand_dims(cam, axis=2)\n",
    "cam = np.tile(cam, [1,1,3])\n",
    "\n",
    "# Create a heatmap out of the CAM data and give a new colormap\n",
    "heatmap = np.uint8(255 * cam)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "''' Now we want to do an overlay of the heatmap to our image'''\n",
    "\n",
    "# Resize the image (need to squeeze/reshape because of the dimensions)\n",
    "image_resized = cv2.resize(image.squeeze(), upsample_shape, interpolation=cv2.INTER_LINEAR) #(300,300)\n",
    "image_resized = np.expand_dims(image_resized, axis=2)\n",
    "#image_resized = np.tile(image_resized, [1,1,3])\n",
    "image_resized = np.uint8(255*image_resized)\n",
    "#image_resized = cv2.cvtColor(image_resized, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "# Create the superimposed image \n",
    "superimposed = heatmap*0.5 + image_resized*0.3\n",
    "superimposed = np.uint8((255*superimposed)/superimposed.max())\n",
    "superimposed = cv2.cvtColor(superimposed, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Plot the images\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image_resized, cmap=plt.cm.binary)\n",
    "plt.colorbar()\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Image\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(superimposed,cmap=plt.cm.RdBu_r)\n",
    "plt.colorbar()\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"CAM\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided Backpropagation (GBP)\n",
    "Idea: neurons act like detectors of particular image features\n",
    "* We are only interested in what image features the neuron detects, not in what kind of stuff it doesn’t detect\n",
    "* So when propagating the gradient, we set all the negative gradients to 0 (ReLU)\n",
    "* We don’t care if a pixel “suppresses” a neuron somewhere along the part to our neuron\n",
    "\n",
    "Thus we want to calulate a GBP vor vizualizing the `saliency` (Strahlung) of the nework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    \"\"\"Same normalization as in:\n",
    "    https://github.com/fchollet/keras/blob/master/examples/conv_filter_visualization.py\n",
    "    \"\"\"\n",
    "    # normalize tensor: center on 0., ensure std is 0.25\n",
    "    x = x.copy()\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + tf.keras.backend.epsilon())\n",
    "    x *= 0.25\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "gbp_model = None\n",
    "gbp_model = tf.keras.models.Model([model.inputs], [conv_layer.output])\n",
    "\n",
    "\n",
    "# @tf.custom_gradient\n",
    "# def guidedRelu(x):\n",
    "#     def grad(dy):\n",
    "#         return tf.cast(dy > 0, \"float32\") * tf.cast(x > 0, \"float32\") * dy\n",
    "\n",
    "#     return tf.nn.relu(x), grad\n",
    "\n",
    "# layer_dict = [layer for layer in gbp_model.layers[1:] if hasattr(layer, \"activation\")]\n",
    "# for layer in layer_dict:\n",
    "#     if layer.activation == tf.keras.activations.relu:\n",
    "#         layer.activation = guidedRelu\n",
    "\n",
    "# Get the Gradient of the input image w.r.t the conv_output\n",
    "with tf.GradientTape() as tape:\n",
    "    inputs = tf.cast(image, tf.float32)\n",
    "    tape.watch(inputs)\n",
    "    convOuts = gbp_model(inputs)\n",
    "    \n",
    "grads_gb = tape.gradient(convOuts, inputs)[0]\n",
    "\n",
    "# # Zero Out negative values\n",
    "\n",
    "grads_gb = np.maximum(grads_gb, 0) # Same as Relu\n",
    "# grads_gb = grads_gb / np.max(grads_gb)\n",
    "\n",
    "\n",
    "# Resize the gradients to match the heatmap\n",
    "saliency_resized = cv2.resize(np.asarray(grads_gb).squeeze(), upsample_shape)\n",
    "saliency_resized = np.expand_dims(saliency_resized, 2)\n",
    "#saliency_resized = np.tile(saliency_resized, [1,1,3]) # Not necessary but now all have the same shapes\n",
    "\n",
    "# Now we create the guided backprop by multiplying the saliecy (gradients) with the heatmap\n",
    "guided_backprop = saliency_resized * heatmap\n",
    "#guided_backprop = deprocess_image(guided_backprop)\n",
    "guided_backprop = np.uint8((255*guided_backprop)/guided_backprop.max())\n",
    "#guided_backprop = cv2.normalize(guided_backprop, guided_backprop, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "guided_backprop = cv2.cvtColor(guided_backprop, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "# Plot the images\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(image_resized, cmap=plt.cm.binary)\n",
    "plt.colorbar()\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Image\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(superimposed,cmap=plt.cm.RdBu_r)\n",
    "plt.colorbar()\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"CAM\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(guided_backprop,cmap=plt.cm.RdBu_r)\n",
    "plt.colorbar()\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"GBP\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": " Workshop tutorial_deep_learning_basics.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/lexfridman/mit-deep-learning/blob/master/tutorial_deep_learning_basics/deep_learning_basics.ipynb",
     "timestamp": 1601022100465
    }
   ],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
